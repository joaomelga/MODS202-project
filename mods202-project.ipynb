{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "---\n",
    "**1. State the fundamental hypothesis under which the Ordinary Least Squares (OLS) estimators are unbiased.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let $y$ and $x$ be two variables representing some population and, since the goal is to state the dependent variable $y$ in terms of the explanatory variable $x$, we write the simple linear regression model:\n",
    "\n",
    "$$\n",
    "y = \\beta_{0} + \\beta_{1} x + u,\n",
    "$$\n",
    "\n",
    "where the variable $u$ is the disturbance term, standed as well for the unobserved variable, which measures the effect of the change in $y$ with $x$ being unobserved. Moreover, $\\beta_{0}$ is the intercept parameter and $\\beta_{1}$ is called the slope parameter, because, considering $u$ fixed, then $\\Delta u = 0$, and the variation of $y$ is linear with variation of $x$, *i.e.*,\n",
    "\n",
    "$$\n",
    "\\Delta y = \\beta_{1} \\Delta x.\n",
    "$$\n",
    "\n",
    "In order to compute the estimators of $\\beta_{0}$ and $\\beta_{1}$, it is necessary to know the relation beteween the variables $u$ and $x$. To that, we can fist assume that the average alue of $u$ is zero, *i.e.*, \n",
    "\n",
    "$$\n",
    "E(u) = 0.\n",
    "$$\n",
    "\n",
    "Defining the the coditional distribution of $u$ given $x$ and assuming that the average of $u$ does not depend on the value of $x$, we arrive in the following equality:\n",
    "\n",
    "$$\n",
    "E(u|x) = E(u) = 0.\n",
    "$$\n",
    "\n",
    "Finally, considering the equation above and applying the expectation on the simple linear regression model, we obtain:\n",
    "\n",
    "$$\n",
    "E(y|x) = \\beta_{0} +  \\beta_{1} x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2. Show that under this assumption the OLS estimators are indeed unbiased.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to derive the Ordinary Least Squares (OLS) estimators, we consider $n$ samples $(x_{i}, y_{i})$ with $i = 1, \\cdots, n$, described by\n",
    "\n",
    "$$\n",
    "y_{i} = \\beta_{0} + \\beta_{1} x_{i} + u_{i}.\n",
    "$$\n",
    "\n",
    "From the equation above, it is possible to isolate $u_{i}$ and, then, use the fundamental hypothesis compute the estimators $\\hat \\beta_{0}$ and $\\hat \\beta_{1}$, by the method of moments.\n",
    "\n",
    "$$\n",
    "u_{i} = y_{i} - \\beta_{0} - \\beta_{1} x_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(u_{i}) = 0 \\iff E(y_{i} - \\beta_{0} - \\beta_{1} x_{i}) = 0\n",
    "\\iff \\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i) = 0 \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad (1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Cov(x,u) = E(xu) = 0 \\iff E(x_{i}(y_{i} - \\beta_{0} - \\beta_{1} x_{i})) = 0 \n",
    "\\iff \\frac{1}{n}\\sum_{i=1}^{n}x_i(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i) = 0 \\quad \\quad (2)\n",
    "$$\n",
    "\n",
    "Starting from the equations above, we obtaing the following system of equations, which will be solved for the variables $\\hat \\beta_{0}$ and $\\hat \\beta_{1}$.\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{matrix}\n",
    "\\sum_{i=1}^{n}y_i - n \\hat \\beta_0 - \\hat \\beta_1 \\sum_{i=1}^{n} x_i = 0 \\quad \\quad \\quad \\quad \\quad \\quad \\quad (3)\\\\ \n",
    "\\\\\n",
    "\\sum_{i=1}^{n}x_iy_i - \\hat \\beta_0 \\sum_{i=1}^{n} x_{i} - \\hat \\beta_1 \\sum_{i=1}^{n} x_i^{2} = 0 \\quad \\quad \\quad (4)\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "From the equation $(3)$, we obtain that \n",
    "\n",
    "$$\n",
    "\\hat \\beta_0 = \\bar{y} - \\hat \\beta_1 \\bar{x}, \\quad \\quad (5)\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_{i} \\quad \\text{and} \\quad \\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n}y_{i}.\n",
    "$$\n",
    "\n",
    "We now substitute the equation $(5)$ in the equation $(2)$, which gives us the following result:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_{i} \\left(y_{i} - (\\bar{y} - \\hat \\beta_{1} \\bar{x}) - \\hat \\beta_{1} x_{i}\\right) = 0\n",
    "\\iff \\sum_{i=1}^{n} x_{i} (y_{i} - \\bar{y}) = \\hat \\beta_{1} \\sum_{i=1}^{n} x_{i} (x_{i} - \\bar{x}) \\quad \\quad (6)\n",
    "$$\n",
    "\n",
    "By using the following results, we can rewrite the equation $(6)$ and, therefore, isolate $\\hat \\beta_{1}$.\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} x_{i} (y_{i} - \\bar{y}) = \\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y}) \\quad \\text{and} \\quad \n",
    "\\sum_{i=1}^{n} x_{i} (x_{i} - \\bar{x}) = \\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2} > 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat \\beta_{1} = \\frac{\\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}} \\quad \\quad (7)\n",
    "$$\n",
    "\n",
    "In conclusion, the OLS estimators are given  by\n",
    "\n",
    "$$\n",
    "\\hat \\beta_{0} = \\bar{y} - \\hat \\beta_{1} \\bar{x} \\quad \\text{and} \\quad \\hat \\beta_{1} = \\frac{\\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}},\n",
    "$$\n",
    "\n",
    "where $\\bar{x}$ and $\\bar{y}$ are the means considering $n$ samples of the independent and dependent variables.\n",
    "\n",
    "Now that the estimators have been computed, the goal is to prove that they are unbiased, by calculating their respective expectations. To that, we rewrite the expression of $\\hat \\beta_{1}$ as follows:\n",
    "\n",
    "First, let $s_{x}^{2} = \\sum_{i=1}^{n}(x_{i} - \\bar{x})^{2}$. Then, $\\hat \\beta_{1}$ can we writen as:\n",
    "\n",
    "$$\n",
    "\\hat \\beta_{1} = \\frac{\\sum_{i=1}^{n} y_{i}(x_{i} - \\bar{x})}{\\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}} = \n",
    "\\frac{\\sum_{i=1}^{n} (\\beta_{0} + \\beta_{1} x_{i} + u_{i})(x_{i} - \\bar{x})}{s_{x}^{2}} = \n",
    "\\frac{\\beta_{0} \\sum_{i=1}^{n} (x_{i} - \\bar{x}) + \\beta_{1} \\sum_{i=1}^{n} (x_{i} - \\bar{x}) x_{i} + \\sum_{i=1}^{n} (x_{i} - \\bar{x}) u_{i}}{s_{x}^{2}}\n",
    "$$\n",
    "\n",
    "From the expression above, we know that \n",
    "* $\\sum_{i=1}^{n} (x_{i} - \\bar{x}) = 0$\n",
    "\n",
    "* $\\sum_{i=1}^{n} (x_{i} - \\bar{x}) x_{i} = s_{x}^{2}$\n",
    "\n",
    "* $x_{i} - \\bar{x} = d_{i}$\n",
    "\n",
    "It turns out, then, that the slope estimator will be given by:\n",
    "\n",
    "$$\n",
    "\\hat \\beta_{1} = \\frac{\\beta_{1} s_{x}^{2} + \\sum_{i=1}^{n} d_{i} u_{i}}{s_{x}^{2}} = \n",
    "\\beta_{1} + \\frac{1}{s_{x}^{2}} \\sum_{i=1}^{n} d_{i} u_{i}\n",
    "$$\n",
    "\n",
    "Then, the bias of the estimator $\\hat \\beta_{1}$ is computed:\n",
    "\n",
    "$$\n",
    "b(\\beta_{1}, \\hat \\beta_{1}) = E(\\hat \\beta_{1}) - \\beta_{1} = \\beta_{1} + \\left( \\frac{1}{s_{x}^{2}} \\sum_{i=1}^{n} E(d_{i} u_{i}) \\right) - \\beta_{1} = \n",
    "\\frac{1}{s_{x}^{2}} \\sum_{i=1}^{n} d_{i} E(u_{i})\n",
    "$$\n",
    "\n",
    "Given that, by hypothesis, $E(u_{i}) = 0$, then the estimator $\\hat \\beta_{1}$ is unbiased, because $b(\\beta_{1}, \\hat \\beta_{1}) = 0$.\n",
    "\n",
    "We do the same procedure for $\\hat \\beta_{0}$, starting by writing it as a function of $\\bar{x}$ and $\\bar{u}$:\n",
    "\n",
    "$$\n",
    "\\hat \\beta_{0} = (\\beta_{0} + \\beta_{1} \\bar{x} + \\bar{u}) - \\hat \\beta_{1} \\bar{x} = \\beta_{0} + (\\beta_{1} - \\hat \\beta_{1}) \\bar{x} + \\bar{u}\n",
    "$$\n",
    "\n",
    "Finally, the bias of the estimator $\\hat \\beta_{0}$ will be given by:\n",
    "\n",
    "$$\n",
    "b(\\beta_{0}, \\hat \\beta_{0}) = E(\\hat \\beta_{0}) - \\beta_{0} = \\beta_{0} + E\\left((\\beta_{1} - \\hat \\beta_{1}) \\bar{x}\\right) + E(\\bar{u}) - \\beta_{0}\n",
    "$$\n",
    "\n",
    "By hypothesis, $E(u_{i}) = 0$ and, given that it was already proved that $E(\\hat \\beta_{1}) = \\beta_{1}$, then, $E\\left((\\beta_{1} - \\hat \\beta_{1}) \\bar{x}\\right) = 0$.\n",
    "\n",
    "From this, we conclude that $b(\\beta_{0}, \\hat \\beta_{0}) = 0$, which means that the estimator is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**3. Explain the sample selection bias with an example from the course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample selection bias occurs when the OLS estimator is affected by using data resulting from non-random sample selection. In an example involving fertilizer and land quality, seen in the course, the issue arises when experiments aren't entirely randomized. Factors known to the experimenter, such as sunlight exposure or susceptibility to pests, may influence the application of fertilizer, leading to sample selection bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**4. Explain the omitted variable bias with an example from the course**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phenomenon happens when there is an exclusion of a relevant variable from the model. Generelly, in this case, the OLS estimators tend to be biased. To prove that, we first consider the true population model, consisting of two explanatory variables and one error term:\n",
    "\n",
    "$$\n",
    "y = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + u.\n",
    "$$\n",
    "\n",
    "If we perform a simple linear regression of $y$ on $x_{1}$ exclusively, *i.e.*, we ignore $x_{2}$, we obtain an underspecified model, given by:\n",
    "\n",
    "$$\n",
    "\\widetilde{y} = \\widetilde{\\beta_{0}} + \\widetilde{\\beta_{1}} x_{1}\n",
    "$$\n",
    "\n",
    "If we derive an expression for $\\widetilde{\\beta_{1}}$, we will otain the a similar equation as $(7)$, as follows:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\beta_{1}} = \\frac{\\sum_{i=1}^{n} y_{i}(x_{i1} - \\bar{x}_{1})}{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1})^{2}} \\quad \\quad \\quad \\quad (8)\n",
    "$$\n",
    "\n",
    "Next, considering the true model, for each observation $i$, we can write\n",
    "\n",
    "$$\n",
    "y_{i} = \\beta_{0} + \\beta_{1} x_{i1} + \\beta_{2} x_{i2} + u_{i} \\quad \\quad (9)\n",
    "$$\n",
    "\n",
    "Substituting $(9)$ in $(8)$, the numerator of $(8)$ will be given by:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (\\beta_{0} + \\beta_{1} x_{i1} + \\beta_{2} x_{i2} + u_{i})(x_{i1} - \\bar{x}_{1}) = \n",
    "\\beta_{1} \\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1})^{2} + \\beta_{2} \\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1}) x_{i2} + \\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1}) u_{i} \\quad \\quad (10)\n",
    "$$\n",
    "\n",
    "With $(10)$, the equation $(8)$ can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\beta_{1}} = \\beta_{1} + \\beta_{2} \\frac{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1}) x_{i2}}{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1})^{2}} + \\frac{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1}) u_{i}}{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1})^{2}} \\quad \\quad (11)\n",
    "$$\n",
    "\n",
    "Finally, using the fact that $E(u_{i}) = 0$, we take the expectation of the estimator $\\widetilde{\\beta_{1}}$:\n",
    "\n",
    "$$\n",
    "E(\\widetilde{\\beta_{1}}) = \\beta_{1} + \\beta_{2} \\frac{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1}) x_{i2}}{\\sum_{i=1}^{n} (x_{i1} - \\bar{x}_{1})^{2}} \\neq \\beta_{1},\n",
    "$$\n",
    "\n",
    "which leads to the fact that $\\widetilde{\\beta_{1}}$ is biased.\n",
    "\n",
    "One example seen in the course, was the following model:\n",
    "\n",
    "$$\n",
    "wage = \\beta_{0} + \\beta_{1} education + \\beta_{2} ability + u\n",
    "$$\n",
    "\n",
    "The bias of the estimator of $\\beta_{1}$ was verified after having underspecified the model by running a simple linear regression of $wage$ on $education$, despising the $ability$ term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**5. Explain the problem of multicollinearity. Is it a problem in this dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue of multicollinearity arises when two or more columns of the matrix $ X $ are linearly dependent (or nearly so).\n",
    "\n",
    "If this is the case, the determinant of the matrix $X^{\\prime}X$ becomes zero or nearly zero.\n",
    "\n",
    "$$\n",
    "det(X^\\prime X) = 0 \n",
    "$$\n",
    "\n",
    "In such instances, the matrix $ (X^\\prime X) $ is non-invertible, rendering the computation of the OLS estimator impossible.\n",
    "\n",
    "A potential remedy for this problem involves either removing one of the linearly dependent columns or introducing additional observations to the dataset.\n",
    "\n",
    "Fortunately, the dataset for this project does not exhibit multicollinearity issues since the determinant of the matrix $ (X^\\prime X) $ is non-zero, as evidenced in the code below:\n",
    "\n",
    "TO DO: talk about R-square influence in multicollineartiy (page 95), talk about VIF = 1 / (1 - R-square)\n",
    "TO DO: discuss that the \"importance\" on multicollinearity depends on how big beta_i is compared to its std_error. A high multicollinearity leads into high Var(beta_i), what becomes a problem depending on the magnitude of beta_i\n",
    "\n",
    "Wooldridge says: \"[...] for statistical inference, what ultimately matters is how big beta_j is in relation to its standard deviation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import t\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "raw_data_path = 'textfiles/HPRICE2.raw'\n",
    "labels_path = 'textfiles/HPRICE2.DES'\n",
    "\n",
    "raw_data = np.loadtxt(raw_data_path)\n",
    "\n",
    "# TO DO: read \\n in the labels file\n",
    "with open(labels_path, 'r') as file:\n",
    "    file.readline()\n",
    "    file.readline()\n",
    "\n",
    "    labels_line = file.readline().strip()\n",
    "    labels = np.array(labels_line.split())\n",
    "\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns=labels)\n",
    "\n",
    "Y = df['price']\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = X.columns \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))] \n",
    "# Exibir os resultados\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**6. Create three categories of nox levels (low, medium, high), corresponding to the following percentiles: 0-25%, 26%-74%, 75%-100%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nox_percentiles_threshholds = np.percentile(df['nox'], [25, 50, 75])\n",
    "nox_categories = np.digitize(df['nox'], nox_percentiles_threshholds)\n",
    "\n",
    "df['nox_category'] = nox_categories\n",
    "\n",
    "low_nox = df[df['nox_category'] == 0]\n",
    "medium_nox = df[df['nox_category'] == 1]\n",
    "high_nox = df[df['nox_category'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "7. Compute for each category of nox level the average median price and comment on your\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Price means')\n",
    "print('Low NOx: ', round(low_nox['price'].mean(), 2))\n",
    "print('Medium NOx: ', round(medium_nox['price'].mean(), 2))\n",
    "print('High NOx: ', round(high_nox['price'].mean(), 2))\n",
    "\n",
    "# TO DO: comment the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "8. Produce a scatter plot with the variable price on the y-axis and the variable nox on the x-axis. Is this a ceteris paribus effect? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['nox'], df['price'])\n",
    "plt.xlabel('nox')\n",
    "plt.ylabel('price')\n",
    "plt.title('Scatter Plot: nox vs price')\n",
    "plt.show()\n",
    "\n",
    "# TO DO: comment the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "9. Run a regression of price on a constant, crime, nox, rooms, proptax. Comment on the histogram of the residuals. Interpret all coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the independent variables\n",
    "X = df[['crime', 'nox', 'rooms', 'proptax']]\n",
    "X = sm.add_constant(X)  # Add a constant column\n",
    "\n",
    "# Define the dependent variable\n",
    "y = df['price']\n",
    "\n",
    "# Fit the regression model\n",
    "model_fit_q9 = sm.OLS(y, X).fit()\n",
    "residuals = model_fit_q9.resid\n",
    "\n",
    "print('Question 9')\n",
    "print('Var(u|X) = ', round(np.var(residuals), 2))\n",
    "print(model_fit_q9.summary())\n",
    "\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# TO DO: comment the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: talk about big variance of u\n",
    "\n",
    "Interpretations\n",
    "\n",
    "**All constant (intercept)**: -18,680\n",
    "- When all independent variables (crime, nox, rooms, proptax) are zero, the predicted value of the dependent variable (price) is -18,680. This may not have much sense.\n",
    "\n",
    "**Variable \"crime\":**: -136.5438\n",
    "- Holding other variables constant, a one-unit increase in the \"crime\" variable is associated with a decrease in the predicted value of the price by 136.5438 units.\n",
    "\n",
    "**Variable \"nox\":**: -660.4672\n",
    "- Holding other variables constant, a one-unit increase in the \"nox\" variable is associated with a decrease in the predicted value of the price by 660.4672 units.\n",
    "\n",
    "**Variable \"rooms\":**: 7797.9286\n",
    "- Holding other variables constant, a one-unit increase in the \"rooms\" variable is associated with an increase in the predicted value of the price by 7797.9286 units.\n",
    "\n",
    "**Variable \"proptax\":**: -89.4144\n",
    "- Holding other variables constant, a one-unit increase in the \"proptax\" variable is associated with a decrease in the predicted value of the price by 89.4144 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "10. Run a regression of lprice on a constant, crime, nox, rooms, proptax. Comment on the histogram of the residuals. Interpret all coefficients. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the independent variables\n",
    "X = df[['crime', 'nox', 'rooms', 'proptax']]\n",
    "X = sm.add_constant(X)  # Add a constant column\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df['lprice']\n",
    "\n",
    "# Fit the regression model\n",
    "model_fit_q10 = sm.OLS(Y, X).fit()\n",
    "residuals = model.resid\n",
    "\n",
    "print('Question 10')\n",
    "print('Var(u|X) = ', round(np.var(residuals), 2))\n",
    "print(model_fit_q10.summary())\n",
    "\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretations\n",
    "\n",
    "**All constant (intercept)**: 8.6550\n",
    "- When all independent variables (crime, nox, rooms, proptax) are zero, the predicted value of the price is 8.6550.\n",
    "\n",
    "**Variable \"crime\"**: -0.0125\n",
    "- Holding other variables constant, a one-unit increase in the \"crime\" variable is associated with a decrease in the predicted value of the price by 0.0125 units.\n",
    "\n",
    "**Variable \"nox\"**: -0.0476\n",
    "- Holding other variables constant, a one-unit increase in the \"nox\" variable is associated with a decrease in the predicted value of the price by 0.0476 units.\n",
    "\n",
    "**Variable \"rooms\"**: 0.2816\n",
    "- Holding other variables constant, a one-unit increase in the \"rooms\" variable is associated with an increase in the predicted value of the price by 0.2816 units.\n",
    "\n",
    "**Variable \"proptax\"**: -0.0043\n",
    "- Holding other variables constant, a one-unit increase in the \"proptax\" variable is associated with a decrease in the predicted value of the price by 0.0043 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "11. Run a regression of lprice on a constant, crime, lnox, rooms, lproptax. Comment on the histogram of the residuals. Interpret all coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variables\n",
    "X = df[['crime', 'lnox', 'rooms', 'proptax']]\n",
    "X = sm.add_constant(X)  # Add a constant column\n",
    "\n",
    "# Define the dependent variable\n",
    "y = df['lprice']\n",
    "\n",
    "# Fit the regression model\n",
    "model_fit_q11 = sm.OLS(y, X).fit()\n",
    "residuals = model_fit_q11.resid\n",
    "\n",
    "print('Question 11')\n",
    "print('Var(u|X) = ', round(np.var(residuals), 2))\n",
    "print(model_fit_q11.summary())\n",
    "\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All constant (intercept)**: 8.8553\n",
    "- When all independent variables (crime, nox, rooms, proptax) are zero, the predicted value of the price is 8.8553.\n",
    "\n",
    "**Variable \"crime\"**: -0.0125\n",
    "- Holding other variables constant, a one-unit increase in the \"crime\" variable is associated with a decrease in the predicted value of the price by 0.0125 units.\n",
    "\n",
    "**Variable \"nox\"**: -0.0476\n",
    "- Holding other variables constant, a one-unit increase in the \"nox\" variable is associated with a decrease in the predicted value of the price by 0.0476 units.\n",
    "\n",
    "**Variable \"rooms\"**: 0.2816\n",
    "- Holding other variables constant, a one-unit increase in the \"rooms\" variable is associated with an increase in the predicted value of the price by 0.2816 units.\n",
    "\n",
    "**Variable \"proptax\"**: -0.0042\n",
    "- Holding other variables constant, a one-unit increase in the \"proptax\" variable is associated with a decrease in the predicted value of the price by 0.0042 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "12. In the specification of question 10, test the hypothesis H0: $\\beta_{nox}$ <0 vs. H1: $\\beta_{nox}$ > 0 at the 1% level.\n",
    "\n",
    "TO DO: add explanation\n",
    "To DO: mention ': Given the observed value of the t statistic, what is the smallest\n",
    "significance level at which the null hypothesis would be rejected? This level is known\n",
    "as the p-value for the test'\n",
    "\n",
    "' In order\n",
    "to compute p-values, we either need extremely detailed printed tables of the t distribution—which is not very practical—or a computer program that computes areas\n",
    "under the probability density function of the t distribution'\n",
    "\n",
    "' If a regression package reports a\n",
    "p-value along with the standard OLS output, it is almost certainly the p-value for testing the null hypothesis H0: \u0001j  0 against the two-sided alternative.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_nox = model_fit_q10.params['nox']\n",
    "se_nox = model_fit_q10.bse['nox']\n",
    "\n",
    "# t-statistic\n",
    "t_value = beta_nox / se_nox\n",
    "deg_freedom = model_fit_q10.df_resid\n",
    "\n",
    "# One-sided p-value\n",
    "p_value_one_tailed = 1 - t.cdf(abs(t_value), deg_freedom)\n",
    "alpha = 0.01\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value_one_tailed < alpha:\n",
    "    print(f'Reject the null hypothesis. p-value: {p_value_one_tailed:.7f}')\n",
    "else:\n",
    "    print(\n",
    "        f'Fail to reject the null hypothesis. p-value: {p_value_one_tailed:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "13. In the specification of question 10, test the hypothesis H0: $\\beta_{nox}$ = 0 vs. H1: $\\beta_{nox}$ ≠ 0 at the 1% level using the p-value of the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_nox = model_fit_q10.params['nox']\n",
    "se_nox = model_fit_q10.bse['nox']\n",
    "\n",
    "# t-statistic\n",
    "t_value = beta_nox / se_nox\n",
    "\n",
    "# Two-sided p-value\n",
    "p_value_two_tailed = 2 * (1 - t.cdf(abs(t_value), deg_freedom))\n",
    "alpha = 0.01\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value_two_tailed < alpha:\n",
    "    print(f'Reject the null hypothesis. p-value: {p_value_two_tailed:.7f}')\n",
    "else:\n",
    "    print(\n",
    "        f'Fail to reject the null hypothesis. p-value: {p_value_two_tailed:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "14. In the specification of question 10, test the hypothesis H0: $\\beta_{crime}$ = $\\beta_{proptax}$ at the 10% level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" cov_matrix = model.cov_params()\n",
    "\n",
    "beta_crime = model.params['crime']\n",
    "beta_proptax = model.params['proptax']\n",
    "\n",
    "se_crime = model.bse['crime']\n",
    "se_proptax = model.bse['proptax']\n",
    "\n",
    "cov_crime_proptax = cov_matrix.loc['crime', 'proptax']\n",
    "se_crime_minus_proptax = np.sqrt(se_crime**2 + se_proptax**2 - 2 * cov_crime_proptax)\n",
    "\n",
    "# t-statistic\n",
    "t_value = (beta_crime - beta_proptax) / se_crime_minus_proptax\n",
    "deg_freedom = model.df_resid\n",
    "\n",
    "# One-sided p-value\n",
    "p_value = 1 - t.cdf(abs(t_value), deg_freedom) \"\"\"\n",
    "\n",
    "alpha = 0.1\n",
    "hypothesis = '(crime = proptax)'\n",
    "\n",
    "p_value = model_fit_q10.f_test(hypothesis).pvalue\n",
    "\n",
    "# Compare the p-value with the significance level\n",
    "if p_value < alpha:\n",
    "    print(f'Reject the null hypothesis. p-value: {p_value:.7f}')\n",
    "else:\n",
    "    print(\n",
    "        f'Fail to reject the null hypothesis. p-value: {p_value:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "15. In the specification of question 10, test the hypothesis H0: $\\beta_{crime}$ = 0, $\\beta_{proptax}$ = 0 at the 10% level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. p-value: 0.000000000000025293764225682351\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Define X unrestricted and restricted\n",
    "Xur = df[['crime', 'nox', 'rooms', 'proptax']]\n",
    "Xur = sm.add_constant(Xur)\n",
    "\n",
    "Xr = df[['nox', 'rooms']]\n",
    "Xr = sm.add_constant(Xr)\n",
    "\n",
    "Y = df['lprice']\n",
    "\n",
    "modelUr = sm.OLS(Y, Xur).fit()\n",
    "modelR = sm.OLS(Y, Xr).fit()\n",
    "\n",
    "SSRur = modelUr.ssr\n",
    "SSRr = modelR.ssr\n",
    "\n",
    "alpha = 0.1\n",
    "q = modelR.df_resid - modelUr.df_resid\n",
    "n_k_1 = modelUr.df_resid\n",
    "\n",
    "F = ((SSRr - SSRur) / q) / (SSRur / n_k_1)\n",
    "p_value = 1 - f.cdf(F, q, n_k_1) \"\"\"\n",
    "\n",
    "alpha = 0.1\n",
    "hypothesis = '(proptax = 0), (nox = 0)'\n",
    "\n",
    "p_value = model_fit_q10.f_test(hypothesis).pvalue\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f'Reject the null hypothesis. p-value: {p_value:.30f}')\n",
    "else:\n",
    "    print(\n",
    "        f'Fail to reject the null hypothesis. p-value: {p_value:.30f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "16. In the specification of question 10, test the hypothesis H0: $\\beta_{crime}$ = -500, $\\beta_{proptax}$ = -100 at the 10% level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. p-value: 0.000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Define X unrestricted and restricted\n",
    "Xur = df[['crime', 'nox', 'rooms', 'proptax']]\n",
    "Xur = sm.add_constant(Xur)\n",
    "\n",
    "Xr = df[['nox', 'rooms']]\n",
    "Xr = sm.add_constant(Xr)\n",
    "\n",
    "Yur = df['lprice']\n",
    "Yr = df['lprice'] - 500*df['crime'] - 100*df['proptax']\n",
    "\n",
    "modelUr = sm.OLS(Yur, Xur).fit()\n",
    "modelR = sm.OLS(Yr, Xr).fit()\n",
    "\n",
    "SSRur = modelUr.ssr\n",
    "SSRr = modelR.ssr\n",
    "\n",
    "alpha = 0.1\n",
    "q = modelR.df_resid - modelUr.df_resid\n",
    "n_k_1 = modelUr.df_resid\n",
    "\n",
    "F = ((SSRr - SSRur) / q) / (SSRur / n_k_1)\n",
    "p_value = 1 - f.cdf(F, q, n_k_1) \"\"\"\n",
    "\n",
    "alpha = 0.1\n",
    "hypothesis = '(proptax = -100), (nox = -500)'\n",
    "\n",
    "p_value = model_fit_q10.f_test(hypothesis).pvalue\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f'Reject the null hypothesis. p-value: {p_value:.30f}')\n",
    "else:\n",
    "    print(\n",
    "        f'Fail to reject the null hypothesis. p-value: {p_value:.30f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "17. In the specification of question 10, test the hypothesis H0: $\\beta_{crime}$ + $\\beta_{proptax}$ = -1000 at the 10% level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. p-value: 0.000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Define X unrestricted and restricted\n",
    "Xur = df[['crime', 'nox', 'rooms', 'proptax']]\n",
    "Xur = sm.add_constant(Xur)\n",
    "\n",
    "Xr_ = df[['nox', 'rooms']]\n",
    "Xr_ = sm.add_constant(Xr_)\n",
    "\n",
    "Yur = df['lprice']\n",
    "Yr = df['lprice'] - 1000*(df['crime'] + df['proptax'])\n",
    "\n",
    "modelUr = sm.OLS(Yur, Xur).fit()\n",
    "modelR = sm.OLS(Yr, Xr).fit()\n",
    "\n",
    "SSRur = modelUr.ssr\n",
    "SSRr = modelR.ssr\n",
    "\n",
    "alpha = 0.1\n",
    "q = modelR.df_resid - modelUr.df_resid\n",
    "n_k_1 = modelUr.df_resid\n",
    "\n",
    "F = ((SSRr - SSRur) / q) / (SSRur / n_k_1)\n",
    "p_value = 1 - f.cdf(F, q, n_k_1) \"\"\"\n",
    "\n",
    "alpha = 0.1\n",
    "hypothesis = '(proptax + nox = -1000)'\n",
    "\n",
    "p_value = model_fit_q10.f_test(hypothesis).pvalue\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f'Reject the null hypothesis. p-value: {p_value:.30f}')\n",
    "else:\n",
    "    print(\n",
    "        f'Fail to reject the null hypothesis. p-value: {p_value:.30f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "18. In the specification of question 10, test the hypothesis that all coefficients are the same for observations with low levels of nox vs. medium and high levels of nox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "19. Repeat the test of question 18 but now assuming that only the coefficients of nox and proptax can change between the two groups of observations. State and test H0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
