{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681beab0",
   "metadata": {},
   "source": [
    "## PART 2 - HETEROSKEDASTICITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5cae6",
   "metadata": {},
   "source": [
    "---\n",
    "**20. Explain the problem of heteroskedasticity with an example of the course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb99678",
   "metadata": {},
   "source": [
    "Firstly, under homoskedasticity, the variances of the error term $u$ and the dependent variable $y$ are assumed to be constant, *i.e.*, \n",
    "\n",
    "$$\n",
    "Var(u|x) = Var(y|x) = \\sigma^{2}\n",
    "$$\n",
    "\n",
    "However, under heteroskedasticity conditions, what happens is that the variance of the error $Var(u|x)$ depends on the independent variable $x$. Consequently, the variance of $y$ $Var(y|x)$ will also depend on $x$. This violation of the homoskedasticity assumption can lead to issues, such as biased standard errors and inefficient parameter estimates in Ordinary Least Squares regression.\n",
    "\n",
    "In the example studied in course, the examination of the education-wage relationship underscores the challenge posed by heteroskedasticity. The quest for an unbiased estimation of education's impact on wages necessitates the assumption $E(u|educ) = 0$, accompanied by the assumption of homoskedasticity $Var(u∣educ) = \\sigma^{2}$. This implies constant wage variance $Var(wage∣educ) = \\sigma^{2}$ across education levels, allowing for varying mean wages while assuming consistent variance. However, the realism concern is acknowledged: higher education levels may introduce greater wage variability due to diverse job opportunities, contrasting with lower variability at lower education levels.\n",
    "\n",
    "Expanding on this, assume we build a model assuming homoskedasticity, implying constant error term variance across education levels. In the real world, individuals with higher education may experience more diverse work opportunities, leading to increased wage variability. Conversely, those with lower education levels may face fewer opportunities, resulting in reduced wage variability. Thus, insisting on homoskedasticity introduces bias into the model, as it overlooks the varying wage volatility associated with different education levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf0139",
   "metadata": {},
   "source": [
    "---\n",
    "**21. Suppose that $ E(u u')= \\sigma^2 \\Omega$. Show that the GLS estimator is the best linear unbiased estimator.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d79ff6",
   "metadata": {},
   "source": [
    "Fistly, considering the model $y = X \\beta + u$, where $E(u|X) = 0$, we derive the expression of the OLS estimator of $\\beta$, called $b$. Considering a set of $n$ i.i.d. observations, the collected data is represented by the following esquation:\n",
    "\n",
    "$$\n",
    "y = X b + u \\quad \\quad \\quad \\quad (12)\n",
    "$$\n",
    "\n",
    "By expliciting the matrix notation of the equation (12), we obtain the following equivalent equation:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{N}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\cdots & x_{1K}\\\\ \n",
    "x_{21} & x_{21} & \\cdots & x_{2K}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\ \n",
    "x_{N1} & x_{N2} & \\cdots & x_{NK} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{K}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "u_{1}\\\\\n",
    "u_{2}\\\\\n",
    "\\vdots\\\\\n",
    "u_{N}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In order to derive an expression for $b$, we minimize sum of the squared residuals, i.e., we minimize\n",
    "\n",
    "$$\n",
    "u' u = \\begin{bmatrix}\n",
    "u_{1}\\ u_{2}\\ \\cdots\\ u_{N}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "u_{1}\\\\\n",
    "u_{2}\\\\\n",
    "\\vdots\\\\\n",
    "u_{N}\n",
    "\\end{bmatrix}= \\sum_{i=1}^{N} u_{i}^{2}\n",
    "$$\n",
    "\n",
    "To that, it is first necessary to isolate the expression of $u$ and then, compute its transpose, so that the product $u' u$ can be minimized. From the equation (12), is given by:\n",
    "\n",
    "$$\n",
    "u = y - X b \\Rightarrow u' = (y - X b)' = y' - b' X'\n",
    "$$\n",
    "\n",
    "Thus, the product to be minimized is:\n",
    "\n",
    "$$\n",
    "u' u = (y' - b' X')(y - X b) = y'y - y'Xb - b'X'y + b'X'Xb \n",
    "$$\n",
    "\n",
    "By noting that $b'X'y = (b'X'y)' = y'Xb$, we arrive in the following expression:\n",
    "\n",
    "$$\n",
    "\\text{min } u'u = y'y - 2b'X'y + b'X'Xb \\quad \\quad (13)\n",
    "$$\n",
    "\n",
    "Finally, what is necessary to do is to take the partial derivative of the equation $(13)$ with respect to $b$ and solve it when it is equal to zero. To that, we use the two following results:\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{matrix}\n",
    "\\frac{\\partial}{\\partial b} (b'X'y) = X'y \\\\ \n",
    "\\frac{\\partial}{\\partial b} (b'X'Xb) = 2X'Xb \n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "With the above, the equation to be solved for $b$ will be:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b} (u'u) = 0 \\iff -2X'y + 2X'Xb = 0 \\iff X'Xb = X'y \\iff b = (X'X)^{-1}X'y \\quad (14)\n",
    "$$\n",
    "\n",
    "Now that the estimator has been computed as shown in the equation $(14)$, to shown that it is the best linear unbiased estimator (BLUE), we first check that it is linear. Indeed, the linearity is checked immediately by seeing the linear relatioship between $b$ and the dependent variable $y$. The second step is to show its unbiasedness. To that, we compute its expected value.\n",
    "\n",
    "$$\n",
    "E(b) = E\\left((X'X)^{-1}X'y\\right) = (X'X)^{-1}X'E(y) \\quad \\quad (15)\n",
    "$$\n",
    "\n",
    "Since the assumption $E(u|X) = 0$ holds, then $E(y) = X \\beta$ and the equation $(15)$ can be written as follows, proving that the estimator $b$ is unbiased.\n",
    "\n",
    "$$\n",
    "E(b) = (X'X)^{-1}(X'X) \\beta \\iff E(b) = \\beta\n",
    "$$\n",
    "\n",
    "Now, for the next steps, it is useful to rewrite the expression of $b$ as follows:\n",
    "\n",
    "$$\n",
    "\\left.\\begin{matrix}\n",
    "y = X \\beta + u \\\\ \n",
    "b = (X'X)^{-1}X'y\n",
    "\\end{matrix}\\right\\}\\Rightarrow \n",
    "b = \\beta + (X'X)^{-1}X'u \\quad \\quad (16)\n",
    "$$\n",
    "\n",
    "With the equation $(16)$, we compute the variance of the estimator considering the Heteroskedasticity supposition that $Var(u) = E(uu') = \\sigma^{2}\\Omega$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Var(b) &= Var\\left(\\beta + (X'X)^{-1}X'u\\right) \\\\\n",
    "       &= Var\\left((X'X)^{-1}X'u\\right) \\\\\n",
    "       &= (X'X)^{-1}X' Var(u) X(X'X)^{-1} \\\\\n",
    "       &= (X'X)^{-1}X' \\sigma^{2} \\Omega X(X'X)^{-1}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, the equation $(17)$ contains the result of the variance of the estimator, considering Heteroskedasticity.\n",
    "\n",
    "$$\n",
    "Var(b) = \\sigma^{2} (X'X)^{-1}X' \\Omega X(X'X)^{-1} \\quad \\quad (17)\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89c4b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a7bec3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5c3714",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aef805d3",
   "metadata": {},
   "source": [
    "## PART 3 - TIME SERIES DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e928e",
   "metadata": {},
   "source": [
    "---\n",
    "**27. Define strict and weak stationarity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287916a7",
   "metadata": {},
   "source": [
    "* **Strict stationarity:** A time series process is considered strictly stationary if the joint probability distribution of its observations remains invariant under shifts in time. In other words, for any set of time points, the entire probability distribution of the data, including the mean, variance, and higher-order moments, remains constant. This implies that all statistical properties of the time series are unchanged over time, making strict stationarity a more stringent condition compared to covariance stationarity, for example.\n",
    "\n",
    "\n",
    "* **Weak stationarity:** A time series process is said to be weak stationary if it presents constants mean, variance and autocorrelation structutre over time, but not its entire probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348594a",
   "metadata": {},
   "source": [
    "---\n",
    "**28. Explain ergodicity and state the ergodic theorem. Illustrate with an example.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700de9ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d110eb7c",
   "metadata": {},
   "source": [
    "---\n",
    "**29. Why do we need both stationarity and ergodicity?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634249b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3619876e",
   "metadata": {},
   "source": [
    "---\n",
    "**30. Explain “spurious regression”.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4cecc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04fe22fb",
   "metadata": {},
   "source": [
    "---\n",
    "**31. Define a moving average and explain the trade-off involved in the choice of the size of the window and of whether to center or not the moving average.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c84542",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33fff9ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59921869",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbf9703e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
