{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "1. State the fundamental hypothesis under which the Ordinary Least Squares (OLS) estimators are unbiased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let $y$ and $x$ be two variables representing some population and, since the goal is to state the dependent variable $y$ in terms of the explanatory variable $x$, we write the simple linear regression model:\n",
    "\n",
    "$$\n",
    "y = \\beta_{0} + \\beta_{1} x + u,\n",
    "$$\n",
    "\n",
    "where the variable $u$ is the disturbance term, standed as well for the unobserved variable, which measures the effect of the change in $y$ with $x$ being unobserved. Moreover, $\\beta_{0}$ is the intercept parameter and $\\beta_{1}$ is called the slope parameter, because, considering $u$ fixed, then $\\Delta u = 0$, and the variation of $y$ is linear with variation of $x$, *i.e.*,\n",
    "\n",
    "$$\n",
    "\\Delta y = \\beta_{1} \\Delta x.\n",
    "$$\n",
    "\n",
    "In order to compute the estimators of $\\beta_{0}$ and $\\beta_{1}$, it is necessary to know the relation beteween the variables $u$ and $x$. To that, we can fist assume that the average alue of $u$ is zero, *i.e.*, \n",
    "\n",
    "$$\n",
    "E(u) = 0.\n",
    "$$\n",
    "\n",
    "Defining the the coditional distribution of $u$ given $x$ and assuming that the average of $u$ does not depend on the value of $x$, we arrive in the following equality:\n",
    "\n",
    "$$\n",
    "E(u|x) = E(u) = 0.\n",
    "$$\n",
    "\n",
    "Finally, considering the equation above and applying the expectation on the simple linear regression model, we obtain:\n",
    "\n",
    "$$\n",
    "E(y|x) = \\beta_{0} +  \\beta_{1} x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Show that under this assumption the OLS estimators are indeed unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to derive the Ordinary Least Squares (OLS) estimators, we consider $n$ samples $(x_{i}, y_{i})$ with $i = 1, \\cdots n$, described by\n",
    "\n",
    "$$\n",
    "y_{i} = \\beta_{0} + \\beta_{1} x_{i} + u_{i}.\n",
    "$$\n",
    "\n",
    "From the equation above, it is possible to isolate $u_{i}$ and, then, use the fundamental hypothesis compute the estimators $\\hat \\beta_{0}$ and $\\hat \\beta_{1}$, by the method of moments.\n",
    "\n",
    "$$\n",
    "u_{i} = y_{i} - \\beta_{0} - \\beta_{1} x_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E(u_{i}) = 0 \\iff E(y_{i} - \\beta_{0} - \\beta_{1} x_{i}) = 0\n",
    "\\iff \\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i) = 0\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Cov(x,u) = E(xu) = 0 \\iff E(x_{i}(y_{i} - \\beta_{0} - \\beta_{1} x_{i})) = 0 \n",
    "\\iff \\frac{1}{n}\\sum_{i=1}^{n}x_i(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i) = 0 \n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will first find the estimators $\\hat \\beta_0$ and $\\hat \\beta_1$ of the coefficients $\\beta_0$ and $\\beta_1$, respectivaly, in the linear model. Then we will prove that these estimators are unbiased.\n",
    "\n",
    "The linear model is given by:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1x + u $$\n",
    "\n",
    "where $y$ is the dependent variable, $x$ is the independent variable, and $u$ is the error term.\n",
    "\n",
    "To estimate the coefficients, we will use the Ordinary Least Squares (OLS) method. We assume that we have a sample of population $x_i$ and $y_i$, where $i = 1, 2, ..., n$ and $n$ is the number of observations. So we can write the above equation for the samples as:\n",
    "\n",
    "The linear model equation for the samples is given by:\n",
    "\n",
    "$$ y_i = \\beta_0 + \\beta_1x_i + u_i $$\n",
    "\n",
    "\n",
    "Isolanting the error for each sample we have that:\n",
    "\n",
    "$$ u_i = y_i - \\beta_0 - \\beta_1x_i $$\n",
    "\n",
    "Now we use the fundamental hypothesis for the last exercice to derive the estimators.\n",
    "\n",
    "$$E(u_i) = E(y_i - \\beta_0 - \\beta_1x_i) = 0 \\quad\\quad\\quad\\quad\\quad$$ \n",
    "\n",
    "$$Cov(u_i,x_i) = E(x_i u_i) = E(x(y_i - \\beta_0 - \\beta_1x_i))= 0  \\quad\\quad\\quad $$ \n",
    "\n",
    "\n",
    "Developing these equations  by the definition of expectation follows that:\n",
    "\n",
    "$$ \n",
    "n^{-1} \\sum_{i=1}^{n}(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i) = 0 \\quad\\quad\\quad\\quad\\quad (i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "n^{-1}\\sum_{i=1}^{n}x_i(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i) = 0 \\quad\\quad\\quad\\quad\\quad (ii)\n",
    "$$\n",
    "\n",
    "Opening the summation on $(i)$ we have that:\n",
    "\n",
    "$$ \\hat \\beta_0 = \\frac{1}{n}\\sum_{i=1}^{n}y_i - \\hat \\beta_1 \\frac{1}{n}\\sum_{i=1}^{n}x_i $$\n",
    "\n",
    "Wich can be written as:\n",
    "\n",
    "$$ \\hat \\beta_0 = \\bar y - \\hat \\beta_1 \\bar x \\quad\\quad\\quad\\quad\\quad (I)$$\n",
    "\n",
    "Now, for the second expression $(ii)$ we drop the term $n^{-1}$ and substitute the value of $\\hat \\beta_0$ from $(I)$:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n}x_i(y_i - (\\bar y - \\hat \\beta_1 \\bar x )- \\hat \\beta_1x_i) = 0 \n",
    "$$\n",
    "\n",
    "Which, upon rearrangement, gives:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n}x_i(y_i-\\bar y) =\\hat \\beta_1 \\sum_{i=1}^{n}x_i (x_i - \\bar x)\n",
    "$$\n",
    "\n",
    "From basic properties of the summation operator:\n",
    "\n",
    "$\\sum_{i=1}^{n}x_i(y_i-\\bar y) =\\sum_{i=1}^{n}(x_i-\\bar x)(y_i-\\bar y)$ and $ \\sum_{i=1}^{n}x_i (x_i - \\bar x) = \\sum_{i=1}^{n}(x_i-\\bar x)^2$\n",
    "\n",
    "Then, we find that $\\beta_1$ is:\n",
    "\n",
    "$$ \\hat \\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar x)(y_i - \\bar y)}{\\sum_{i=1}^{n}(x_i - \\bar x)^2} \\quad\\quad\\quad\\quad\\quad (II)$$\n",
    "\n",
    "can be written as:\n",
    "\n",
    "Finally, the OLS estimators are given by:\n",
    "\n",
    "$$ \\hat \\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar x)(y_i - \\bar y)}{\\sum_{i=1}^{n}(x_i - \\bar x)^2} $$\n",
    "\n",
    "$$ \\hat \\beta_0 = \\bar y - \\hat \\beta_1 \\bar x $$\n",
    "\n",
    "where $n$ is the number of observations, $x_i$ and $y_i$ are the values of the independent and dependent variables, respectively, and $\\bar x$ and $\\bar y$ are the sample means of the independent and dependent variables, respectively.\n",
    "\n",
    "---\n",
    "\n",
    "Now, we can prove that those estimators are unbiased, for this we have to prove that $E(\\hat \\beta_1)=\\beta_1$ and $E(\\hat \\beta_0)=\\beta_0$.\n",
    "\n",
    "We can rewrite the expression of $\\hat \\beta_1$ at $(II)$ using the fact that $\\sum_{i=1}^{n}(x_i-\\bar x)(y_i-\\bar y)=\\sum_{i=1}^{n}y_i(x_i-\\bar x)$:\n",
    "\n",
    "$$ \n",
    " \\hat \\beta_1 = \\frac{\\sum_{i=1}^{n}y_i(x_i-\\bar x)}{\\sum_{i=1}^{n}(x_i - \\bar x)^2} \n",
    "$$\n",
    "\n",
    "Using $s_x^2=\\sum_{i=1}^{n}(x_i - \\bar x)^2$ to simplify the notation and $ y_i = \\beta_0 + \\beta_1x_i + u_i $:\n",
    "\n",
    "$$ \n",
    " \\hat \\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i-\\bar x)(\\beta_0 + \\beta_1x_i + u_i)}{s_x^2} \n",
    "$$\n",
    "\n",
    "First, we open the numerator with the goal to simply it:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n}(x_i-\\bar x)(\\beta_0 + \\beta_1x_i + u_i) = \\sum_{i=1}^{n}(x_i-\\bar x)\\beta_0 + \\sum_{i=1}^{n}(x_i-\\bar x)\\beta_1 x_i + \\sum_{i=1}^{n}(x_i-\\bar x) u_i =  \\beta_0 \\sum_{i=1}^{n}(x_i-\\bar x)+ \\beta_1\\sum_{i=1}^{n}(x_i-\\bar x)x_i +  \\sum_{i=1}^{n}(x_i-\\bar x)u_i\n",
    "$$\n",
    "\n",
    "But, we have that:\n",
    "\n",
    "$\\sum_{i=1}^{n}(x_i-\\bar x)=0$ and $\\sum_{i=1}^{n}(x_i-\\bar x)x_i = \\sum_{i=1}^{n}(x_i-\\bar x)^2=s_x^2$ so the numerator is: $\\beta_1 s_x^2 + \\sum_{i=1}^{n}(x_i-\\bar x)u_i$\n",
    "\n",
    "Which gives us the $\\beta_1$:\n",
    "\n",
    "$$\n",
    "\\hat \\beta_1 =  \\beta_1 + \\frac{\\sum_{i=1}^{n}(x_i-\\bar x)u_i}{s_x^2}\n",
    "$$\n",
    "\n",
    "\n",
    "Now we can compute the expectated value of it:\n",
    "\n",
    "$$ \n",
    "E(\\hat \\beta_1) = E(\\beta_1) + E(\\frac{\\sum_{i=1}^{n}(x_i-\\bar x)u_i}{s_x^2}) = \\beta_1 +(\\frac{1}{s_x^2})\\sum_{i=1}^{n}E((x_i-\\bar x)u_i) = \\beta_1 +(\\frac{1}{s_x^2})\\sum_{i=1}^{n}E((x_i-\\bar x))E(u_i) \n",
    "$$\n",
    "\n",
    "But, as for our assumption $E(u_i)=0$, so $E(\\hat \\beta_1) = \\beta_1$ and we conclude that $\\hat \\beta_1$ is unbiased.\n",
    "\n",
    "For $\\hat \\beta_0$:\n",
    "\n",
    "$$\n",
    "E(\\hat \\beta_0) = E(\\bar y - \\hat \\beta_1 \\bar x) = E((\\beta_0 + \\beta_1 \\bar x + \\bar u) - \\hat \\beta_1 \\bar x) = E(\\beta_0 + (\\beta_1  - \\hat \\beta_1)\\bar x + \\bar u) = \\beta_0 + E((\\beta_1  - \\hat \\beta_1)\\bar x )\n",
    "$$\n",
    "\n",
    "As $E(\\bar u)= 0$ and $E(\\hat \\beta_1) = \\beta_1 $ we have that $E((\\beta_1  - \\hat \\beta_1)\\bar x ) = 0$ and $E(\\hat \\beta_0) = \\beta_0$ and thus, $\\hat \\beta_0$ is unbiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explain the sample selection bias with an example from the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Explain the omitted variable bias with an example from the course "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Explain the problem of multicollinearity. Is it a problem in this dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create three categories of nox levels (low, medium, high), corresponding to the following percentiles: 0-25%, 26%-74%, 75%-100% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>crime</th>\n",
       "      <th>nox</th>\n",
       "      <th>rooms</th>\n",
       "      <th>dist</th>\n",
       "      <th>radial</th>\n",
       "      <th>proptax</th>\n",
       "      <th>stratio</th>\n",
       "      <th>lowstat</th>\n",
       "      <th>lprice</th>\n",
       "      <th>lnox</th>\n",
       "      <th>lproptax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>5.38</td>\n",
       "      <td>6.57</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>10.085810</td>\n",
       "      <td>1.682688</td>\n",
       "      <td>5.690360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21599.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>4.69</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>9.980402</td>\n",
       "      <td>1.545433</td>\n",
       "      <td>5.488938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34700.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>4.69</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>10.454500</td>\n",
       "      <td>1.545433</td>\n",
       "      <td>5.488938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33400.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>4.58</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>10.416310</td>\n",
       "      <td>1.521699</td>\n",
       "      <td>5.402678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36199.0</td>\n",
       "      <td>0.069</td>\n",
       "      <td>4.58</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>10.496790</td>\n",
       "      <td>1.521699</td>\n",
       "      <td>5.402678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22400.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.016820</td>\n",
       "      <td>1.745715</td>\n",
       "      <td>5.609472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20600.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.933046</td>\n",
       "      <td>1.745715</td>\n",
       "      <td>5.609472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>23899.0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.98</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>10.081590</td>\n",
       "      <td>1.745715</td>\n",
       "      <td>5.609472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>22000.0</td>\n",
       "      <td>0.110</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.79</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9.998797</td>\n",
       "      <td>1.745715</td>\n",
       "      <td>5.609472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>11900.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>5.73</td>\n",
       "      <td>6.03</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>9.384294</td>\n",
       "      <td>1.745715</td>\n",
       "      <td>5.609472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  crime   nox  rooms  dist  radial  proptax  stratio  lowstat  \\\n",
       "0    24000.0  0.006  5.38   6.57  4.09     1.0     29.6     15.3     4.98   \n",
       "1    21599.0  0.027  4.69   6.42  4.97     2.0     24.2     17.8     9.14   \n",
       "2    34700.0  0.027  4.69   7.18  4.97     2.0     24.2     17.8     4.03   \n",
       "3    33400.0  0.032  4.58   7.00  6.06     3.0     22.2     18.7     2.94   \n",
       "4    36199.0  0.069  4.58   7.15  6.06     3.0     22.2     18.7     5.33   \n",
       "..       ...    ...   ...    ...   ...     ...      ...      ...      ...   \n",
       "501  22400.0  0.063  5.73   6.59  2.48     1.0     27.3     21.0     9.67   \n",
       "502  20600.0  0.045  5.73   6.12  2.29     1.0     27.3     21.0     9.08   \n",
       "503  23899.0  0.061  5.73   6.98  2.17     1.0     27.3     21.0     5.64   \n",
       "504  22000.0  0.110  5.73   6.79  2.39     1.0     27.3     21.0     6.48   \n",
       "505  11900.0  0.047  5.73   6.03  2.51     1.0     27.3     21.0     7.88   \n",
       "\n",
       "        lprice      lnox  lproptax  \n",
       "0    10.085810  1.682688  5.690360  \n",
       "1     9.980402  1.545433  5.488938  \n",
       "2    10.454500  1.545433  5.488938  \n",
       "3    10.416310  1.521699  5.402678  \n",
       "4    10.496790  1.521699  5.402678  \n",
       "..         ...       ...       ...  \n",
       "501  10.016820  1.745715  5.609472  \n",
       "502   9.933046  1.745715  5.609472  \n",
       "503  10.081590  1.745715  5.609472  \n",
       "504   9.998797  1.745715  5.609472  \n",
       "505   9.384294  1.745715  5.609472  \n",
       "\n",
       "[506 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "raw_data_path = 'textfiles/HPRICE2.raw'\n",
    "labels_path = 'textfiles/HPRICE2.DES'\n",
    "\n",
    "raw_data = np.loadtxt(raw_data_path)\n",
    "\n",
    "with open(labels_path, 'r') as file:\n",
    "    file.readline()\n",
    "    file.readline()\n",
    "    \n",
    "    labels_line = file.readline().strip()\n",
    "    labels = np.array(labels_line.split())\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns=labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
